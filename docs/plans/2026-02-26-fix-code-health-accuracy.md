# Fix code_health Scoring Accuracy

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Source audit:** `docs/audits/2026-02-26-audit-bonanza-code-health.md`
**Goal:** Fix 3 bugs, eliminate 53% false positives, and improve issue quality — validated against bonanza-api.
**Tech Stack:** Go 1.24, go/ast, testify

---

## Task 1: Fix SubMetric Field on Issues (P0 Bug)

**Files:**
- Modify: `internal/domain/scoring/code_health.go` — function `collectCodeHealthIssues`
- Modify: `internal/domain/scoring/code_health_test.go` — add assertion

**What to fix:**

`collectCodeHealthIssues` appends issues without setting the `SubMetric` field. This breaks `skip.sub_metrics` filtering in `score_service.go:209`.

In each issue append block inside `collectCodeHealthIssues`, add the appropriate `SubMetric` value:
- Function size issues: `SubMetric: "function_size"`
- File size issues: `SubMetric: "file_size"`
- Nesting depth issues: `SubMetric: "nesting_depth"`
- Parameter count issues: `SubMetric: "parameter_count"`
- Complex conditional issues: `SubMetric: "complex_conditionals"`

**Test:** Add test that scores a project with `skip.sub_metrics: [function_size]` and verifies NO code_health issues have `SubMetric == "function_size"`.

**Verify:** `go test ./internal/domain/scoring/ -run TestCodeHealth -v -count=1`

---

## Task 2: Fix Zero-Function Edge Case (P0 Bug)

**Files:**
- Modify: `internal/domain/scoring/code_health.go` — all `score*` functions
- Modify: `internal/domain/scoring/code_health_test.go`

**What to fix:**

When `total == 0` (no functions to evaluate), the four function-based sub-metrics return `Score: 0`. A project with no functions has no violations — score should be full credit.

In `scoreFunctionSize`, `scoreNestingDepth`, `scoreParameterCount`, `scoreComplexConditionals`: when `total == 0`, set `sm.Score = sm.Points` and `sm.Detail = "no functions to evaluate"`.

**Test:** Score an `analyzed` map with a single file that has 0 functions. Verify all four function-based sub-metrics return full points.

**Verify:** `go test ./internal/domain/scoring/ -run TestCodeHealth -v -count=1`

---

## Task 3: Use math.Round Instead of int() (P0 Bug)

**Files:**
- Modify: `internal/domain/scoring/code_health.go` — all `score*` functions

**What to fix:**

Replace all instances of:
```go
sm.Score = int(ratio * float64(sm.Points))
```
with:
```go
sm.Score = int(math.Round(ratio * float64(sm.Points)))
```

This shifts the cliff boundary from 95.0% → 97.5% for the 19→20 transition, making scoring more intuitive.

Add `"math"` to imports.

**Test:** Verify that a ratio of 0.975 yields 20/20 (currently yields 19). Verify ratio of 0.924 yields 18/20 (not 19).

**Verify:** `go test ./internal/domain/scoring/ -run TestCodeHealth -v -count=1`

---

## Task 4: Detect and Exclude Generated Code (P1)

**Files:**
- Modify: `internal/domain/ports.go` — add `IsGenerated bool` field to `AnalyzedFile`
- Modify: `internal/adapters/outbound/parser/go_parser.go` — detect `// Code generated` comment
- Modify: `internal/domain/scoring/code_health.go` — skip generated files
- Modify tests for parser and code_health

**What to build:**

**Parser change:** In `AnalyzeFile`, after parsing the AST, check if the file starts with a `// Code generated` comment (Go convention per `go generate` docs). Set `af.IsGenerated = true` if found.

Detection logic:
```go
for _, cg := range file.Comments {
    for _, c := range cg.List {
        if strings.Contains(c.Text, "Code generated") && strings.Contains(c.Text, "DO NOT EDIT") {
            af.IsGenerated = true
            break
        }
    }
    break // only check first comment group
}
```

**Scoring change:** In all five `score*` functions and `collectCodeHealthIssues`, skip files where `af.IsGenerated == true`.

**Test:**
- Parser: create a temp file with `// Code generated by sqlc. DO NOT EDIT.` header, verify `IsGenerated == true`.
- Parser: normal file, verify `IsGenerated == false`.
- Scoring: include a generated file with a 1000-line function, verify it doesn't affect score or generate issues.

**Verify:** `go test ./internal/adapters/outbound/parser/ ./internal/domain/scoring/ -v -count=1`

---

## Task 5: Relaxed Scoring for Test Files (P1)

**Files:**
- Modify: `internal/domain/scoring/code_health.go` — all five `score*` functions and `collectCodeHealthIssues`

**What to fix:**

For files ending in `_test.go`, apply doubled thresholds:
- function_size: `MaxFunctionLines * 2` for full credit (instead of `MaxFunctionLines`)
- file_size: `MaxFileLines * 2` for full credit
- nesting_depth: `MaxNestingDepth + 1` for full credit
- parameter_count: `MaxParameters + 2` for full credit
- complex_conditionals: `MaxConditionalOps + 1` for full credit

The issue thresholds should also be doubled for test files.

**Implementation:** Add a helper:
```go
func isTestFile(path string) bool {
    return strings.HasSuffix(path, "_test.go")
}
```

In each scoring loop, check `isTestFile(af.Path)` and use relaxed thresholds.

**Test:** Score a project where a `_test.go` file has a 90-line function (under relaxed limit of 100) — verify full credit. Same function in a non-test file — verify partial credit.

**Verify:** `go test ./internal/domain/scoring/ -run TestCodeHealth -v -count=1`

---

## Task 6: Severity Tiering for Issues (P1)

**Files:**
- Modify: `internal/domain/scoring/code_health.go` — `collectCodeHealthIssues`

**What to fix:**

Replace hardcoded `SeverityWarning` with ratio-based severity:

```go
func issueSeverity(actual, threshold int) string {
    ratio := float64(actual) / float64(threshold)
    switch {
    case ratio >= 3.0:
        return domain.SeverityError
    case ratio >= 1.5:
        return domain.SeverityWarning
    default:
        return domain.SeverityInfo
    }
}
```

Ensure `domain.SeverityError`, `SeverityWarning`, `SeverityInfo` constants exist (check model.go).

**Examples after fix:**
- `ReconstructCustomer` (69 params, threshold 7): ratio 9.9 → **error**
- `CreateProduct` (108 lines, threshold 100): ratio 1.08 → **info**
- `supervision_tx_helpers_test.go` (891 lines, threshold 500): ratio 1.78 → **warning**

**Test:** Verify that a function with 21 params (3x threshold of 7) gets `SeverityError`. A function with 8 params (1.1x) gets `SeverityInfo`.

**Verify:** `go test ./internal/domain/scoring/ -run TestCodeHealth -v -count=1`

---

## Task 7: Exempt Reconstruct Pattern from parameter_count (P1)

**Files:**
- Modify: `internal/domain/scoring/code_health.go` — `scoreParameterCount` and `collectCodeHealthIssues`

**What to fix:**

Functions matching the `Reconstruct*` prefix are DDD reconstruction functions that map DB columns to domain entities with unexported fields. Their high parameter count is architectural, not a code smell.

In `scoreParameterCount`, when a function name starts with "Reconstruct", give it full credit regardless of parameter count. In `collectCodeHealthIssues`, do not emit parameter_count issues for `Reconstruct*` functions.

```go
if strings.HasPrefix(fn.Name, "Reconstruct") {
    earned += 1.0 // full credit for reconstruction pattern
    continue
}
```

**Test:** Score a file with `ReconstructCustomer(69 params)` — verify it gets full credit and no issue. Score a file with `ProcessOrder(10 params)` — verify it still gets zero credit and an issue.

**Verify:** `go test ./internal/domain/scoring/ -run TestCodeHealth -v -count=1`

---

## Task 8: Populate Pattern Field and Group Issues (P2)

**Files:**
- Modify: `internal/domain/scoring/code_health.go` — `collectCodeHealthIssues`

**What to fix:**

Set the `Pattern` field on issues to enable grouping:
- Functions starting with `Reconstruct`: `Pattern: "reconstruct"`
- Functions starting with `New`: `Pattern: "constructor"`
- Functions starting with `Test`: `Pattern: "test"`
- Files in paths containing `sqlc/` or `_gen.go`: `Pattern: "generated"`
- All others: `Pattern: ""`

This is informational — no logic depends on it yet, but it enables future grouping and filtering.

**Test:** Verify that a Reconstruct function issue has `Pattern: "reconstruct"` and a test function issue has `Pattern: "test"`.

**Verify:** `go test ./internal/domain/scoring/ -run TestCodeHealth -v -count=1`

---

## Task 9: Validate Against bonanza-api

**No files to modify — validation only.**

```bash
# 1. Build
go build -o ./openkraft ./cmd/openkraft

# 2. Score bonanza-api
./openkraft score /Users/aldrichcortero/Developer/bonanza-api --json | python3 -c "
import json, sys
data = json.load(sys.stdin)
ch = [c for c in data['categories'] if c['name'] == 'code_health'][0]
print(f'Score: {ch[\"score\"]}/100')
print(f'Issues: {len(ch.get(\"issues\", []))}')
for s in ch['sub_metrics']:
    print(f'  {s[\"name\"]}: {s[\"score\"]}/{s[\"points\"]} — {s[\"detail\"]}')
# Count by severity
from collections import Counter
sev = Counter(i['severity'] for i in ch.get('issues', []))
print(f'Severity breakdown: {dict(sev)}')
# Count by pattern
pat = Counter(i.get('pattern', '') for i in ch.get('issues', []))
print(f'Pattern breakdown: {dict(pat)}')
"
```

**Expected results:**
- Score drops from 91 to ~80-85 (more accurate, less diluted)
- Issues drop from 456 to ~200 (generated code and Reconstruct exempted)
- Issues have severity tiering (error/warning/info)
- Issues have SubMetric and Pattern populated
- No generated code issues
- Test file issues use relaxed thresholds

```bash
# 3. Full test suite
go test ./... -count=1

# 4. Score openkraft itself — ensure no regression
./openkraft score . --json | python3 -c "
import json, sys
data = json.load(sys.stdin)
print(f'Overall: {data[\"overall\"]}')
for c in data['categories']:
    print(f'  {c[\"name\"]}: {c[\"score\"]}')
"
```

---

## Execution Order

```
Task 1-3: P0 Bugs (SubMetric, zero-function, math.Round)
Task 4-5: P1 Filtering (generated code, test files)
Task 6-7: P1 Accuracy (severity tiering, Reconstruct exemption)
Task 8:   P2 UX (Pattern field)
Task 9:   Validation against bonanza-api
```

Each task group should be committed separately. Run `go test ./internal/domain/scoring/ -count=1` after each task.
